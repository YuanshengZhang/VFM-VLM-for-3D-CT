## VFM and VLFM for 3D CT scans

[VFM and VLM for 3D CT scans](https://github.com/YuanshengZhang/VFM-VLM-for-3D-CT/) is the comprehensive review that includes:

* the latest publicly available Vision Foundation Models (VFMs) and Vision-Language Foundation Models (VLFMs) specifically designed for 3D Computed Tomography (CT);
* the latest publicly available 3D CT dataset;
* the overview of metrics employed for evaluating VFM and VLM;


### The list of medical VLFMs for 3D CT

| VLFM | Vision Encoder | Pretraining Data | Downstream task | Paper | Code | Year |
|------|------|------|------|------|------|------|
| RadFM | 3D ViT | 16M 2D+3D multimodal | diagnosis, visual question answering, report generation | [Wu et al.](https://www.nature.com/articles/s41467-025-62385-7) | [GitHub](https://github.com/chaoyi-wu/RadFM) |2025|



### The list of 3D CT Datasets

| Medical Dataset | Anatomical Targets | Image-Text pairs | QA pairs | Paper | Link |
|------|------|------|------|------|
| CT-ORG | 140 CT scans containing six organ classes: liver, lungs, bladder, kidney, bones and brain | - | - | [Rister et al.]([https://link.springer.com/chapter/10.1007/978-3-030-01364-6_20](https://www.nature.com/articles/s41597-020-00715-8)) | [GitHub](https://www.cancerimagingarchive.net/collection/ct-org/) |
